{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ace7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "####                               IMPORTING\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()) + '/model/remimo')\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from model.remimo.sample_generator import sample_generator\n",
    "from model.remimo.iterative_classifier import iterative_classifier\n",
    "from model.remimo.utils_remimo import *\n",
    "\n",
    "################################################################################\n",
    "#\n",
    "####                              SETTINGS\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "######################\n",
    "###  General setup ###\n",
    "######################\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "data_filename = str(Path(os.getcwd()).parent.absolute()) + '/data/H_bank.mat'\n",
    "data_filename_test = str(Path(os.getcwd()).parent.absolute()) + '/data/H_bank2.mat'\n",
    "\n",
    "mat_contents = sio.loadmat(data_filename)\n",
    "mat_contents_test = sio.loadmat(data_filename_test)\n",
    "\n",
    "useGPU = True # If true, and GPU is available, use it.\n",
    "#\\\\\\ Determine processing unit:\n",
    "if useGPU and torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "######################\n",
    "### Parameter of the system and model ###\n",
    "######################\n",
    "NR = 64\n",
    "NT_list = np.arange(16, 33)\n",
    "# NT_list = np.arange(4,8)\n",
    "NT_prob = NT_list/NT_list.sum()\n",
    "mod_n = 16\n",
    "d_transmitter_encoding = NR\n",
    "d_model = 512\n",
    "n_head = 8\n",
    "nhid = d_model*4\n",
    "nlayers = 16\n",
    "dropout = 0.0\n",
    "\n",
    "epoch_size = 5000\n",
    "train_iter = 130*epoch_size\n",
    "\n",
    "# Batch sizes for training and validation sets\n",
    "train_batch_size = 256\n",
    "mini_validtn_batch_size = 2500\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "corr_flag = True\n",
    "batch_corr = True\n",
    "rho_low = 0.55\n",
    "rho_high = 0.75\n",
    "\n",
    "validtn_NT_list = np.asarray([16, 32])\n",
    "snrdb_list = {16:np.arange(11.0, 22.0), 32:np.arange(18.0, 25.0)}\n",
    "factor_list = (validtn_NT_list/validtn_NT_list.sum())/snrdb_list[16].size\n",
    "\n",
    "model_filename = './remimo_model_3gpp.pth'\n",
    "curr_accr = './curr_accr.txt'\n",
    "load_pretrained_model = False\n",
    "save_interim_model = True\n",
    "save_to_file = False\n",
    "\n",
    "################################################################################\n",
    "#\n",
    "####                              MAIN\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "\n",
    "######################\n",
    "### Functions ###\n",
    "######################\n",
    "def get_snr_range(NT):\n",
    "    peak = NT*(5.0/16.0) + 6.0\n",
    "    snr_low = peak\n",
    "    snr_high = peak+10.0\n",
    "    return (snr_low, snr_high)\n",
    "\n",
    "\n",
    "def validate_model_given_data(model, validtn_H, validtn_y, validtn_j_indices, validtn_noise_sigma, device, criterion=None):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        validtn_H = validtn_H.to(device=device).float()\n",
    "        validtn_y = validtn_y.to(device=device).float()\n",
    "        validtn_noise_sigma = validtn_noise_sigma.to(device=device).float()\n",
    "        validtn_out = model.forward(validtn_H, validtn_y, validtn_noise_sigma)\n",
    "\n",
    "        if (criterion):\n",
    "            validtn_j_indices = validtn_j_indices.to(device=device)\n",
    "            loss = loss_function(criterion, validtn_out, validtn_j_indices, nlayers)\n",
    "            validtn_j_indices = validtn_j_indices.to(device='cpu')\n",
    "\n",
    "        validtn_out = validtn_out[-1].to(device='cpu')\n",
    "        accr = accuracy(validtn_out, validtn_j_indices)\n",
    "\n",
    "        del validtn_H, validtn_y, validtn_noise_sigma, validtn_out, validtn_j_indices\n",
    "\n",
    "        if (criterion):\n",
    "            return accr, loss.item()\n",
    "        else:\n",
    "            return accr, None\n",
    "\n",
    "def mini_validation(model, mini_validation_dict, i, device, criterion=None, save_to_file=True):\n",
    "    result_dict = {int(NT):{} for NT in validtn_NT_list}\n",
    "    loss_list = []\n",
    "    for index,NT in enumerate(validtn_NT_list):\n",
    "        for snr in snrdb_list[NT]:\n",
    "            big_validtn_H, big_validtn_y, big_validtn_j_indices, big_noise_sigma = mini_validation_dict[NT][snr]\n",
    "            accr, loss = validate_model_given_data(model, big_validtn_H, big_validtn_y, big_validtn_j_indices, big_noise_sigma, device, criterion)\n",
    "            result_dict[NT][snr] = accr\n",
    "            loss_list.append(loss*factor_list[index])\n",
    "\n",
    "    print('Validtn result, Accr for 16 : ', result_dict[16])\n",
    "    print('Validation resut, Accr for 32 : ', result_dict[32])\n",
    "    if (save_to_file):\n",
    "        with open(curr_accr, 'w') as f:\n",
    "            print((i, result_dict), file=f)\n",
    "        print('Saved intermediate validation results at : ', curr_accr)\n",
    "\n",
    "    if (criterion):\n",
    "        return np.sum(loss_list)\n",
    "\n",
    "def generate_big_validtn_data(H, generator, batch_size, corr_flag, rho, batch_corr, rho_low, rho_high):\n",
    "    validtn_data_dict = {int(NT):{} for NT in validtn_NT_list}\n",
    "    for NT in validtn_NT_list:\n",
    "        Haux1 = torch.tensor(H[random.sample(range(3276), mini_validtn_batch_size), :, :])#Pick up NT random users from 100.\n",
    "        Haux = torch.tensor(Haux1[:, :, random.sample(range(100), NT)])#Pick up NT random users from 100.\n",
    "        Hr = torch.real(Haux)\n",
    "        Hi = torch.imag(Haux)\n",
    "        h1 = torch.cat((Hr, -1. * Hi), dim=2)\n",
    "        h2 = torch.cat((Hi, Hr), dim=2)\n",
    "        big_validtn_H = torch.cat((h1, h2), dim=1)\n",
    "\n",
    "        for snr in snrdb_list[NT]:\n",
    "            big_validtn_y, x, big_validtn_j_indices, big_noise_sigma = generator.give_batch_data_Hinput(big_validtn_H, int(NT), snr_db_min=snr, snr_db_max=snr, batch_size=batch_size)\t\n",
    "            validtn_data_dict[int(NT)][snr] = (big_validtn_H, big_validtn_y , big_validtn_j_indices, big_noise_sigma)\n",
    "    return validtn_data_dict\n",
    "\n",
    "def save_model_func(model, optimizer):\n",
    "    torch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, model_filename)\n",
    "    print('******Model Saved********** at directory : ', model_filename)\n",
    "\n",
    "\n",
    "def train(model, optimizer, lr_scheduler, generator , device='cpu'):\n",
    "    H = mat_contents_test['H_bank']\n",
    "    mini_validation_dict = generate_big_validtn_data(H, generator, mini_validtn_batch_size, corr_flag, None, batch_corr, rho_low, rho_high)\n",
    "    # Fix loss criterion\n",
    "    criterion = nn.CrossEntropyLoss().to(device=device)\n",
    "    model.train()\n",
    "    epoch_count = 1\n",
    "\n",
    "    for i in range(1, train_iter+1):\n",
    "\n",
    "        # Randomly select number of transmitters\n",
    "        NT = np.random.choice(NT_list, p=NT_prob)\n",
    "        rho = np.random.triangular(rho_low, rho_high, rho_high)\n",
    "\n",
    "        snr_low, snr_high = get_snr_range(NT)\n",
    "        \n",
    "        H = mat_contents['H_bank']\n",
    "        Haux1 = torch.tensor(H[random.sample(range(3276), train_batch_size), :, :])#Pick up NT random users from 100.\n",
    "        Haux = torch.tensor(Haux1[:, :, random.sample(range(100), NT)])#Pick up NT random users from 100.\n",
    "        Hr = torch.real(Haux)\n",
    "        Hi = torch.imag(Haux)\n",
    "        h1 = torch.cat((Hr, -1. * Hi), dim=2)\n",
    "        h2 = torch.cat((Hi, Hr), dim=2)\n",
    "        H_train = torch.cat((h1, h2), dim=1)\n",
    "        \n",
    "        \n",
    "        y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H_train, NT, snr_db_min=snr_low,\n",
    "                                                                snr_db_max=snr_high, \n",
    "                                                                batch_size = train_batch_size)\n",
    "        H = H_train.to(device=device).float()\n",
    "        y = y.to(device=device).float()\n",
    "        noise_sigma = noise_sigma.to(device=device).float()\n",
    "\n",
    "        out = model.forward(H,y, noise_sigma)\n",
    "\n",
    "        del H, y, noise_sigma\n",
    "\n",
    "        j_indices = j_indices.to(device=device)\n",
    "        loss = loss_function(criterion, out, j_indices, nlayers)\n",
    "        del j_indices, out\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_item = loss.item()\n",
    "        del loss\n",
    "\n",
    "        if (i%epoch_size==0):\n",
    "            print('iteration number : ', i, 'Epoch : ', epoch_count, 'User : ', NT, 'loss : ', loss_item)\n",
    "            print('Now validating')\n",
    "\n",
    "            model.eval()\n",
    "            mini_validtn_loss = mini_validation(model, mini_validation_dict, i, device, criterion, save_to_file)\n",
    "            print('Mini validation loss : ', mini_validtn_loss)\n",
    "            lr_scheduler.step(mini_validtn_loss)\n",
    "\n",
    "            model.train()\n",
    "            if (save_interim_model):\n",
    "                save_model_func(model, optimizer)\n",
    "\n",
    "            epoch_count = epoch_count+1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613389be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82322/2057404024.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Haux = torch.tensor(Haux1[:, :, random.sample(range(100), NT)])#Pick up NT random users from 100.\n",
      "/tmp/ipykernel_82322/2057404024.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Haux = torch.tensor(Haux1[:, :, random.sample(range(100), NT)])#Pick up NT random users from 100.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number :  5000 Epoch :  1 User :  21 loss :  0.675198495388031\n",
      "Now validating\n",
      "Validtn result, Accr for 16 :  {11.0: tensor(0.7867), 12.0: tensor(0.8478), 13.0: tensor(0.8923), 14.0: tensor(0.9275), 15.0: tensor(0.9528), 16.0: tensor(0.9701), 17.0: tensor(0.9814), 18.0: tensor(0.9873), 19.0: tensor(0.9932), 20.0: tensor(0.9951), 21.0: tensor(0.9965)}\n",
      "Validation resut, Accr for 32 :  {18.0: tensor(0.5432), 19.0: tensor(0.5607), 20.0: tensor(0.5786), 21.0: tensor(0.5877), 22.0: tensor(0.5973), 23.0: tensor(0.6100), 24.0: tensor(0.6177)}\n",
      "Mini validation loss :  0.7122161505800304\n",
      "******Model Saved********** at directory :  ./model_3gpp.pth\n",
      "iteration number :  10000 Epoch :  2 User :  22 loss :  0.5933646559715271\n",
      "Now validating\n",
      "Validtn result, Accr for 16 :  {11.0: tensor(0.8128), 12.0: tensor(0.8739), 13.0: tensor(0.9171), 14.0: tensor(0.9487), 15.0: tensor(0.9700), 16.0: tensor(0.9819), 17.0: tensor(0.9914), 18.0: tensor(0.9945), 19.0: tensor(0.9965), 20.0: tensor(0.9982), 21.0: tensor(0.9989)}\n",
      "Validation resut, Accr for 32 :  {18.0: tensor(0.6024), 19.0: tensor(0.6263), 20.0: tensor(0.6552), 21.0: tensor(0.6690), 22.0: tensor(0.6917), 23.0: tensor(0.7055), 24.0: tensor(0.7236)}\n",
      "Mini validation loss :  0.6097910778992103\n",
      "******Model Saved********** at directory :  ./model_3gpp.pth\n",
      "iteration number :  15000 Epoch :  3 User :  31 loss :  0.8468830585479736\n",
      "Now validating\n",
      "Validtn result, Accr for 16 :  {11.0: tensor(0.8458), 12.0: tensor(0.9081), 13.0: tensor(0.9462), 14.0: tensor(0.9707), 15.0: tensor(0.9857), 16.0: tensor(0.9924), 17.0: tensor(0.9963), 18.0: tensor(0.9983), 19.0: tensor(0.9990), 20.0: tensor(0.9994), 21.0: tensor(0.9996)}\n",
      "Validation resut, Accr for 32 :  {18.0: tensor(0.6887), 19.0: tensor(0.7313), 20.0: tensor(0.7735), 21.0: tensor(0.8030), 22.0: tensor(0.8243), 23.0: tensor(0.8517), 24.0: tensor(0.8667)}\n",
      "Mini validation loss :  0.4899804813392234\n",
      "******Model Saved********** at directory :  ./model_3gpp.pth\n",
      "iteration number :  20000 Epoch :  4 User :  18 loss :  0.3238806128501892\n",
      "Now validating\n",
      "Validtn result, Accr for 16 :  {11.0: tensor(0.8525), 12.0: tensor(0.9147), 13.0: tensor(0.9528), 14.0: tensor(0.9784), 15.0: tensor(0.9897), 16.0: tensor(0.9950), 17.0: tensor(0.9981), 18.0: tensor(0.9988), 19.0: tensor(0.9994), 20.0: tensor(0.9995), 21.0: tensor(0.9998)}\n",
      "Validation resut, Accr for 32 :  {18.0: tensor(0.7125), 19.0: tensor(0.7667), 20.0: tensor(0.8067), 21.0: tensor(0.8402), 22.0: tensor(0.8662), 23.0: tensor(0.8862), 24.0: tensor(0.9028)}\n",
      "Mini validation loss :  0.4600921968619028\n",
      "******Model Saved********** at directory :  ./model_3gpp.pth\n",
      "iteration number :  25000 Epoch :  5 User :  25 loss :  0.4487800598144531\n",
      "Now validating\n",
      "Validtn result, Accr for 16 :  {11.0: tensor(0.8523), 12.0: tensor(0.9171), 13.0: tensor(0.9548), 14.0: tensor(0.9790), 15.0: tensor(0.9901), 16.0: tensor(0.9953), 17.0: tensor(0.9968), 18.0: tensor(0.9991), 19.0: tensor(0.9991), 20.0: tensor(0.9998), 21.0: tensor(0.9998)}\n",
      "Validation resut, Accr for 32 :  {18.0: tensor(0.7290), 19.0: tensor(0.7883), 20.0: tensor(0.8274), 21.0: tensor(0.8655), 22.0: tensor(0.8883), 23.0: tensor(0.9113), 24.0: tensor(0.9295)}\n",
      "Mini validation loss :  0.43902312761003315\n",
      "******Model Saved********** at directory :  ./model_3gpp.pth\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#\n",
    "####                              MAIN RUN\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "generator = sample_generator(train_batch_size, mod_n, NR)\n",
    "model = iterative_classifier(d_model, n_head, nhid, nlayers, mod_n, NR, d_transmitter_encoding, generator.real_QAM_const, generator.imag_QAM_const, generator.constellation, device, dropout)\n",
    "model = model.to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "if (load_pretrained_model):\n",
    "    checkpoint = torch.load(model_filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min', 0.91, 0, 0.0001, 'rel', 0, 0, 1e-08, verbose = True)\n",
    "    print('*******Successfully loaded pre-trained model***********')\n",
    "else:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min', 0.91, 0, 0.0001, 'rel', 0, 0, 1e-08, verbose = True)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, generator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da8d1b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Successfully loaded pre-trained model*********** from directory :  ./model_3gpp.pth\n",
      "Big Validtn result, Accr for 16 :  defaultdict(<class 'int'>, {18.0: 0.8689331501831502, 19.0: 0.9278083028083028, 20.0: 0.9579708485958486, 21.0: 0.9762286324786325, 22.0: 0.9879903083028083, 23.0: 0.9942574786324786, 24.0: 0.9960412851037851})\n",
      "Big Validation resut, Accr for 32 :  defaultdict(<class 'int'>, {18.0: 0.8689331501831502, 19.0: 0.9278083028083028, 20.0: 0.9579708485958486, 21.0: 0.9762286324786325, 22.0: 0.9879903083028083, 23.0: 0.9942574786324786, 24.0: 0.9960412851037851})\n",
      "Big Validtn result, Accr for 16 :  defaultdict(<class 'int'>, {18.0: 0.8704641712454212, 19.0: 0.9225355807387057, 20.0: 0.9585503472222222, 21.0: 0.977723882020757, 22.0: 0.9884052579365079, 23.0: 0.9943934104090354, 24.0: 0.9965993208180708})\n",
      "Big Validation resut, Accr for 32 :  defaultdict(<class 'int'>, {18.0: 0.8704641712454212, 19.0: 0.9225355807387057, 20.0: 0.9585503472222222, 21.0: 0.977723882020757, 22.0: 0.9884052579365079, 23.0: 0.9943934104090354, 24.0: 0.9965993208180708})\n",
      "Big Validtn result, Accr for 16 :  defaultdict(<class 'int'>, {18.0: 0.8708695818070817, 19.0: 0.9218559218559218, 20.0: 0.9571420092253425, 21.0: 0.9788169006919006, 22.0: 0.9885880901505901, 23.0: 0.9943019943019943, 24.0: 0.996220407678741})\n",
      "Big Validation resut, Accr for 32 :  defaultdict(<class 'int'>, {18.0: 0.8708695818070817, 19.0: 0.9218559218559218, 20.0: 0.9571420092253425, 21.0: 0.9788169006919006, 22.0: 0.9885880901505901, 23.0: 0.9943019943019943, 24.0: 0.996220407678741})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_240503/3618997270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*******Successfully loaded pre-trained model*********** from directory : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'******************************** Now Testing **********************************************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_240503/3618997270.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, generator, device)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Testing Trained Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidtn_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_240503/3618997270.py\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, generator, device, save_result)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msnr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msnrdb_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mbig_validtn_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_validtn_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_validtn_j_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_noise_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidtn_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0maccr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model_given_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_validtn_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_validtn_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_validtn_j_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_noise_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccr\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_240503/3618997270.py\u001b[0m in \u001b[0;36mvalidate_model_given_data\u001b[0;34m(model, validtn_H, validtn_y, validtn_j_indices, validtn_noise_sigma, device)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mvalidtn_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidtn_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mvalidtn_noise_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidtn_noise_sigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mvalidtn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidtn_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidtn_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidtn_noise_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mvalidtn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidtn_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MIMO_detection_project/Langevin_repo/Langevin-MIMO-detector/model/remimo/iterative_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, H, y, noise_sigma, attn_mask, save_attn_weight)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_decoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterative_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0msout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_attn_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mx_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MIMO_detection_project/Langevin_repo/Langevin-MIMO-detector/model/remimo/EncoderDecoderBlock.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, st, xt, H, y, noise_sigma, NT, index, attn_weights, save_attn_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_attn_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_common_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mencoder_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_attn_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MIMO_detection_project/Langevin_repo/Langevin-MIMO-detector/model/remimo/EncoderDecoderBlock.py\u001b[0m in \u001b[0;36mgen_common_input\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdelta_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_repr_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_repr_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_attn_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#\n",
    "####                              MAIN RUN - TESTING\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pickle as pkl\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()) + '/model/remimo')\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from model.remimo.sample_generator import sample_generator\n",
    "from model.remimo.iterative_classifier import iterative_classifier\n",
    "from model.remimo.utils_remimo import *\n",
    "\n",
    "# Parameters\n",
    "NR = 64\n",
    "NT = 32\n",
    "mod_n = 16\n",
    "d_transmitter_encoding = NR\n",
    "d_model = 512\n",
    "n_head = 8\n",
    "nhid = d_model*4\n",
    "nlayers = 16\n",
    "dropout = 0.0\n",
    "\n",
    "# Batch sizes for training and validation sets\n",
    "validtn_batch_size = 3276\n",
    "validtn_iter = 500\n",
    "\n",
    "M = int(np.sqrt(mod_n))\n",
    "sigConst = np.linspace(-M+1, M-1, M) \n",
    "sigConst /= np.sqrt((sigConst ** 2).mean())\n",
    "sigConst /= np.sqrt(2.) #Each complex transmitted signal will have two parts\n",
    "\n",
    "validtn_NT_list = np.asarray([32, 32])\n",
    "snrdb_list = {16:np.arange(11.0, 19.0), 32:np.arange(18.0, 25.0)}\n",
    "save_result = False\n",
    "\n",
    "dirMainPath = str(Path(os.getcwd()).parent.absolute())\n",
    "data_filename = str(Path(os.getcwd()).parent.absolute()) + '/data/H_bank.mat'\n",
    "data_filename_test = str(Path(os.getcwd()).parent.absolute()) + '/data/H_bank2.mat'\n",
    "\n",
    "mat_contents = sio.loadmat(data_filename)\n",
    "mat_contents_test = sio.loadmat(data_filename_test)\n",
    "\n",
    "validtn_filename = './REMIMO_results'\n",
    "model_filename = './remimo_model_3gpp.pth'\n",
    "\n",
    "\n",
    "def accuracy(out, j_indices):\n",
    "    out = out.permute(1,2,0)\n",
    "    out = out.argmax(dim=1)\n",
    "    accuracy = (out == j_indices).sum().to(dtype=torch.float32)\n",
    "    return accuracy.item()/out.numel()\n",
    "\n",
    "def bit_indices(indices, mod_n):\n",
    "    real_indices = (indices//np.sqrt(mod_n)).to(dtype=torch.int32)\n",
    "    imag_indices = (indices%np.sqrt(mod_n)).to(dtype=torch.int32)\n",
    "    joint_bit_indices = torch.cat((real_indices, imag_indices), dim=-1)\n",
    "    return joint_bit_indices\n",
    "\n",
    "def sym_accuracy(out, j_indices):\n",
    "    accuracy = (out == j_indices).sum().to(dtype=torch.float32)\n",
    "    return accuracy.item()/out.numel()\n",
    "\n",
    "def bit_accuracy(out, j_indices):\n",
    "    out = out.permute(1,2,0)\n",
    "    out = out.argmax(dim=1)\n",
    "    bit_out_indices = bit_indices(out, mod_n)\n",
    "    bit_j_indices = bit_indices(j_indices, mod_n)\n",
    "    return sym_accuracy(bit_out_indices, bit_j_indices)\n",
    "\n",
    "def validate_model_given_data(model, validtn_H, validtn_y, validtn_j_indices, validtn_noise_sigma, device):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        validtn_H = validtn_H.to(device=device).float()\n",
    "        validtn_y = validtn_y.to(device=device).float()\n",
    "        validtn_noise_sigma = validtn_noise_sigma.to(device=device).float()\n",
    "        validtn_out = model.forward(validtn_H, validtn_y, validtn_noise_sigma)\n",
    "\n",
    "        validtn_out = validtn_out[-1].to(device='cpu')\n",
    "        accr = accuracy(validtn_out, validtn_j_indices)\n",
    "\n",
    "        del validtn_H, validtn_y, validtn_out, validtn_noise_sigma\n",
    "\n",
    "    return accr\n",
    "\n",
    "\n",
    "def validate_model(model, generator, device, save_result=True):\n",
    "    H = mat_contents_test['H_bank']\n",
    "    Haux1 = torch.tensor(H[random.sample(range(3276), validtn_batch_size), :, :])#Pick up NT random users from 100.\n",
    "    Haux = torch.tensor(Haux1[:, :, random.sample(range(100), 32)])#Pick up NT random users from 100.\n",
    "\n",
    "    Hr = torch.real(Haux)\n",
    "    Hi = torch.imag(Haux)\n",
    "    h1 = torch.cat((Hr, -1. * Hi), dim=2)\n",
    "    h2 = torch.cat((Hi, Hr), dim=2)\n",
    "    big_validtn_H = torch.cat((h1, h2), dim=1)\n",
    "\n",
    "    result_dict = {int(NT): defaultdict(int) for NT in validtn_NT_list}\n",
    "    for iter in range(validtn_iter):\n",
    "        validtn_data_dict = generate_big_validtn_data(big_validtn_H, generator, validtn_batch_size)\n",
    "        for NT in validtn_NT_list:\n",
    "            for snr in snrdb_list[NT]:\n",
    "                big_validtn_H, big_validtn_y, big_validtn_j_indices, big_noise_sigma = validtn_data_dict[NT][snr]\n",
    "                accr = validate_model_given_data(model, big_validtn_H, big_validtn_y, big_validtn_j_indices, big_noise_sigma, device)\n",
    "                result_dict[NT][snr] =  result_dict[NT][snr] + (accr-result_dict[NT][snr])/float(iter+1.0)\n",
    "\n",
    "        if (save_result):\n",
    "            with open(validtn_filename, 'wb') as handle:\n",
    "                pkl.dump(result_dict, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "            print('Intermediate Test results saved at : ', validtn_filename)\n",
    "        print('Big Validtn result, Accr for 16 : ', result_dict[32])\n",
    "        print('Big Validation resut, Accr for 32 : ', result_dict[32])\n",
    "\n",
    "\n",
    "def generate_big_validtn_data(big_validtn_H, generator, batch_size):\n",
    "    validtn_data_dict = {int(NT):{} for NT in validtn_NT_list}\n",
    "    for NT in validtn_NT_list:\n",
    "\n",
    "        for snr in snrdb_list[NT]:\n",
    "            big_validtn_y, x, big_validtn_j_indices, big_noise_sigma = generator.give_batch_data_Hinput(big_validtn_H, int(NT), snr_db_min=snr, snr_db_max=snr, batch_size=batch_size)\t\n",
    "            validtn_data_dict[int(NT)][snr] = (big_validtn_H, big_validtn_y , big_validtn_j_indices, big_noise_sigma)\n",
    "    return validtn_data_dict\n",
    "\n",
    "def test(model, generator, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Testing Trained Network\n",
    "    validate_model(model, generator, device, save_result)\n",
    "\n",
    "generator = sample_generator(validtn_batch_size, mod_n, NR)\n",
    "device = 'cuda'\n",
    "model = iterative_classifier(d_model, n_head, nhid, nlayers, mod_n, NR, d_transmitter_encoding, generator.real_QAM_const, generator.imag_QAM_const, generator.constellation, device, dropout)\n",
    "model = model.to(device=device)\n",
    "\n",
    "checkpoint = torch.load(model_filename)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('*******Successfully loaded pre-trained model*********** from directory : ', model_filename)\n",
    "\n",
    "test(model, generator, device)\n",
    "print('******************************** Now Testing **********************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21b6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac4117b4f16cf43a7b4d29a08f995b98bcec8327806e376c489c9fe767f71064"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
