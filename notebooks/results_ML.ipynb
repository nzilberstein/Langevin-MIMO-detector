{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\\\\Standard libraries\n",
    "from distutils.command.config import config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import yaml\n",
    "import os\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "# sys.path.append(os.path.dirname(os.getcwd()) + '/data')\n",
    "# sys.path.append(os.path.dirname(os.getcwd()) + '/utils')\n",
    "# sys.path.append(os.path.dirname(os.getcwd()) + '/runners')\n",
    "\n",
    "\n",
    "#\\\\Own libraries\n",
    "from model.ML import *\n",
    "from data.sample_generator import *\n",
    "from utils.util import *\n",
    "from runners.runner_ML import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a189cfc",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89482dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###  Load parameters of the system ###\n",
    "######################\n",
    "dirPath = os.path.dirname(os.getcwd())\n",
    "with open(dirPath + '/config.yml', 'r') as f:\n",
    "    aux = yaml.load(f,  Loader=yaml.FullLoader)\n",
    "config = dict2namespace(aux)\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "###  General setup ###\n",
    "######################\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "useGPU = False # If true, and GPU is available, use it.\n",
    "loadChannelInput = True\n",
    "LANGEVIN_DETECTOR = True\n",
    "CLASSICAL_DETECTORS = True\n",
    "\n",
    "#\\\\\\ Determine processing unit:\n",
    "if useGPU and torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e060c9",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadChannelInput == True:\n",
    "\n",
    "    #\\\\ IID channels\n",
    "    # with open(dirPath + '/data/Hiid_5000bs_3264', 'rb') as fp:\n",
    "    #     H = pkl.load(fp)\n",
    "    # batch_size = H.shape[0]\n",
    "\n",
    "    #\\\\ Kronecker channels\n",
    "    # with open(dirPath + '/data/H_5000bs_3264', 'rb') as fp:\n",
    "    #     H = pkl.load(fp)\n",
    "    # batch_size = H.shape[0]\n",
    "\n",
    "    #\\\\ 3gpp case\n",
    "    # mat_contents = sio.loadmat(dirPath + '/data/H_bank.mat')\n",
    "    # H = mat_contents['H_bank']\n",
    "    # # H = torch.tensor(H[:, :, 0:config.NT])\n",
    "    # H = torch.tensor(H[:, :, random.sample(range(100), config.NT)])#Pick up NT random users from 100.\n",
    "    # batch_size = H.shape[0]\n",
    "    # Hr = torch.real(H)\n",
    "    # Hi = torch.imag(H)\n",
    "\n",
    "    # h1 = torch.cat((Hr, -1. * Hi), dim=2)\n",
    "    # h2 = torch.cat((Hi, Hr), dim=2)\n",
    "    # H = torch.cat((h1, h2), dim=1)\n",
    "\n",
    "    #\\\\ Real channel\n",
    "    int_min = 0\n",
    "    int_max = 200\n",
    "\n",
    "    H, batch_size = loadRealChannels(dirPath, int_min, int_max)\n",
    "\n",
    "    #Create generator\n",
    "    generator = sample_generator(batch_size, config.mod_n, config.NR)\n",
    "else:\n",
    "    batch_size = 5000\n",
    "    generator = sample_generator(batch_size, config.mod_n, config.NR)\n",
    "    H, y, x, j_indices, noise_sigma = generator.give_batch_data(config.NT, \n",
    "                                                                snr_db_min=config.SNR_dBs[config.NT][0], snr_db_max=config.SNR_dBs[config.NT][0], \n",
    "                                                                batch_size=batch_size, correlated_flag=config.corr_flag, rho=config.rho)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f1bdf",
   "metadata": {},
   "source": [
    "Run detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789132b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "serML = runML(config, generator, batch_size, device, H = H)\n",
    "print(serML)\n",
    "# with open(dirPath + '/results/ML_results', \"wb\") as output_file:\n",
    "#     pkl.dump(serML, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirPath + '/results/ML_results', \"wb\") as output_file:\n",
    "    pkl.dump(serML, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146bc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
