{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "# from numpy import linalg as LA\n",
    "import scipy.linalg as LA\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()) + '/model/mmnet')\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "from model.mmnet.utils import *\n",
    "from data.sample_generator import *\n",
    "from model.mmnet.MMNet import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "####                              SETTINGS\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "######################\n",
    "###  Load parameters of the system ###\n",
    "######################\n",
    "dirPath = os.path.dirname(os.getcwd())\n",
    "with open(dirPath + '/config.yml', 'r') as f:\n",
    "    aux = yaml.load(f,  Loader=yaml.FullLoader)\n",
    "config = dict2namespace(aux)\n",
    "\n",
    "\n",
    "######################\n",
    "###  General setup ###\n",
    "######################\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "useGPU = False # If true, and GPU is available, use it.\n",
    "loadChannelInput = True\n",
    "\n",
    "saveModel = False\n",
    "dirPath = str(Path(os.getcwd()).parent.absolute())\n",
    "\n",
    "useGPU = True # If true, and GPU is available, use it.\n",
    "\n",
    "#\\\\\\ Determine processing unit:\n",
    "if useGPU and torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "#Parameters\n",
    "train_iter = 10000\n",
    "train_batch_size = 500\n",
    "learning_rate = 1e-3\n",
    "num_layers = 10\n",
    "\n",
    "\n",
    "if loadChannelInput == True:\n",
    "\n",
    "    # \\\\ IID channels\n",
    "    with open(dirPath + '/data/Hiid_5000bs_3264', 'rb') as fp:\n",
    "        H = pkl.load(fp)\n",
    "    batch_size = H.shape[0]\n",
    "\n",
    "    #Create generator\n",
    "    generator = sample_generator(batch_size, config.mod_n, config.NR)\n",
    "else:\n",
    "    batch_size = 5000\n",
    "    generator = sample_generator(batch_size, config.mod_n, config.NR)\n",
    "    H, y, x, j_indices, noise_sigma = generator.give_batch_data(config.NT, \n",
    "                                                                snr_db_min=config.SNR_dBs[config.NT][0], snr_db_max=config.SNR_dBs[config.NT][0], \n",
    "                                                                batch_size=batch_size, correlated_flag=config.corr_flag, rho=config.rho)  \n",
    "\n",
    "\n",
    "def train(H_test, model, optimizer, generator, config, device='cuda'):\n",
    "    criterion = nn.MSELoss().to(device=device)\n",
    "    model.train()\n",
    "    real_QAM_const = generator.real_QAM_const.to(device=device)\n",
    "    imag_QAM_const = generator.imag_QAM_const.to(device=device)\n",
    "\n",
    "    for i in range(train_iter):\n",
    "\n",
    "        H, y, x, j_indices, noise_sigma = generator.give_batch_data(config.NT, \n",
    "                                                                    snr_db_min=config.SNR_dBs[config.NT][0], snr_db_max=config.SNR_dBs[config.NT][-1], \n",
    "                                                                    batch_size=train_batch_size)  \n",
    "        \n",
    "        H = H.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        noise_sigma = noise_sigma.to(device=device)\n",
    "        \n",
    "        list_batch_x_predicted = model.forward(H, y, noise_sigma, train_batch_size)\n",
    "\n",
    "        x = x.to(device=device)\n",
    "        j_indices = j_indices.to(device=device)\n",
    "\n",
    "        loss, SER = loss_fn(x, list_batch_x_predicted, j_indices, real_QAM_const, imag_QAM_const, criterion, num_layers)                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del y, x, j_indices, noise_sigma, list_batch_x_predicted\n",
    "\n",
    "        if (i%500==0):\n",
    "            model.eval()\n",
    "            H_test = H_test.to(device='cpu')\n",
    "            y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H_test, config.NT, snr_db_min=config.SNR_dBs[config.NT][0], snr_db_max=config.SNR_dBs[config.NT][-1],\n",
    "                                                                         batch_size=batch_size)            \n",
    "            H_test = H_test.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            noise_sigma = noise_sigma.to(device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                list_batch_x_predicted = model.forward(H_test, y, noise_sigma, batch_size)\n",
    "                x = x.to(device=device)\n",
    "                j_indices = j_indices.to(device=device)\n",
    "                loss_last, SER_final = loss_fn(x, list_batch_x_predicted, j_indices, real_QAM_const, imag_QAM_const, criterion, num_layers)                \n",
    "                results = [loss_last.detach().item(), 1 - SER_final]\n",
    "                print_string = [i]+results\n",
    "                print(' '.join('%s' % np.round(x,6) for x in print_string))\n",
    "            del y, x, j_indices, noise_sigma, list_batch_x_predicted\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.496112 0.979212\n",
      "500 0.161388 0.605181\n",
      "1000 0.093234 0.296638\n",
      "1500 0.066246 0.182238\n",
      "2000 0.052808 0.112563\n",
      "2500 0.048206 0.082987\n",
      "3000 0.045975 0.06345\n",
      "3500 0.04523 0.058488\n",
      "4000 0.045186 0.0561\n",
      "4500 0.044541 0.054538\n",
      "5000 0.043226 0.047225\n",
      "5500 0.040987 0.038456\n",
      "6000 0.040065 0.036312\n",
      "6500 0.039167 0.03285\n",
      "7000 0.038903 0.031863\n",
      "7500 0.038408 0.028381\n",
      "8000 0.038166 0.025706\n",
      "8500 0.037784 0.024288\n",
      "9000 0.037657 0.023294\n",
      "9500 0.037781 0.0239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MMNet(num_layers, config.NT, config.NR, generator.constellation, device=device)\n",
    "model = model.to(device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train(H, model, optimizer, generator, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/MIMO_detection_project/Langevin_repo/Langevin-MIMO-detector/model/mmnet/utils.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  H = torch.tensor(test_set)\n"
     ]
    }
   ],
   "source": [
    "## generator = sample_generator(test_batch_size, mod_n, NR)\n",
    "accs_NN = model_eval(config.NT, model, config.SNR_dBs[config.NT][0], config.SNR_dBs[config.NT][-1], batch_size, generator, device, num_layers, iterations=500,  test_set_flag = True, test_set = H)\n",
    "accs_NN\n",
    "\n",
    "serlist = []\n",
    "for ii in range(len(config.SNR_dBs[config.NT])):\n",
    "    serlist.append(accs_NN[ii][1])\n",
    "\n",
    "with open(dirPath + '/results/mmnet_results', \"wb\") as output_file:\n",
    "    pkl.dump(serlist, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac4117b4f16cf43a7b4d29a08f995b98bcec8327806e376c489c9fe767f71064"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
