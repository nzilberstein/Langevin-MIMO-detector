{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import pickle as pkl\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from sample_generator_REMIMO import *\n",
    "from utils import *\n",
    "\n",
    "#parameters\n",
    "NT = 32\n",
    "NR = 64\n",
    "\n",
    "SNR_dBs = {16:np.arange(11.0, 18.0), 32:np.arange(16.0, 22.0), 10:np.arange(16.0, 22.0), 1:np.arange(16.0, 22.0)}\n",
    "# SNR_dBs = {16:np.arange(11.0, 18.0), 32:np.arange(11.0, 17.0), 6:np.arange(0.0, 20.0), 2:np.arange(5.0, 21.0)}#QAM-16 - iid channel\n",
    "# SNR_dBs = {16:np.arange(11.0, 18.0), 32:np.arange(23.0, 29.0), 6:np.arange(10.0, 20.0), 2:np.arange(5.0, 21.0)}#3gpp\n",
    "\n",
    "mod_n = 16\n",
    "\n",
    "corr_flag = True\n",
    "batch_corr = True\n",
    "\n",
    "M = int(np.sqrt(mod_n))\n",
    "sigConst = np.linspace(-M+1, M-1, M) \n",
    "sigConst /= np.sqrt((sigConst ** 2).mean())\n",
    "sigConst /= np.sqrt(2.) \n",
    "rho = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNetwork(nn.Module):\n",
    "    def __init__(self, NT, NR, device):\n",
    "        super(MLPNetwork, self).__init__()\n",
    "        self.input_shape = 4 * NT + 1\n",
    "        self.output_shape = 2 * NT\n",
    "        self.device = device\n",
    "        self.hidden1 = 400\n",
    "        self.hidden2 = 350\n",
    "        self.hidden3 = 100\n",
    "\n",
    "        self.layer1 = nn.Linear(self.input_shape , self.hidden1).to(device=self.device).double()\n",
    "        self.layer2 = nn.Linear(self.hidden1 , self.hidden2).to(device=self.device).double()\n",
    "        self.layer3 = nn.Linear(self.hidden2 , self.hidden3).to(device=self.device).double()\n",
    "        self.layer4 = nn.Linear(self.hidden3, self.output_shape).to(device=self.device).double()\n",
    "\n",
    "        self.layer1.weight = torch.nn.init.xavier_uniform_(self.layer1.weight)\n",
    "        self.layer2.weight = torch.nn.init.xavier_uniform_(self.layer2.weight)\n",
    "        self.layer3.weight = torch.nn.init.xavier_uniform_(self.layer3.weight)\n",
    "        self.layer4.weight = torch.nn.init.xavier_uniform_(self.layer4.weight)\n",
    "\n",
    "\n",
    "    def process_forward(self, H):\n",
    "\n",
    "        output1 = self.layer1(H.double())\n",
    "        norm_output1 = F.elu(output1, alpha = 3)\n",
    "        output2 = self.layer2(norm_output1)\n",
    "        norm_output2 = F.elu(output2, alpha = 3)\n",
    "        output3 = self.layer3(norm_output2)\n",
    "        norm_output3 = F.elu(output3, alpha = 3)\n",
    "        \n",
    "        paramsMainNet = self.layer4(norm_output3)\n",
    "        \n",
    "        return paramsMainNet\n",
    "\n",
    "    def forward(self, H):\n",
    "        return self.process_forward(H)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Langevin(nn.Module):\n",
    "\n",
    "    def __init__(self, NT, sigma_gaussian, generator, n_samples, device='cuda'):\n",
    "        super(Langevin, self).__init__()\n",
    "        self.num_noise_levels = sigma_gaussian.shape[0]\n",
    "        self.generator = generator\n",
    "        self.n_samples = n_samples\n",
    "#         self.step = step\n",
    "        self.device = device\n",
    "        self.sigma_gaussian = sigma_gaussian\n",
    "        # self.MLP_gradient_likelihood = MLPNetwork(NT, NR, device)\n",
    "        self.Langevin_base = nn.ModuleList([Unadjusted_langevin_algorithm(NT, self.generator, self.n_samples, self.device) for i in range(self.num_noise_levels)])\n",
    "    \n",
    "    def forward(self, Z0, singulars, Sigma, Uh, Vh, y, sigma, bs, step):\n",
    "#         Z_init = torch.clone(Z0)\n",
    "        r1 = 1\n",
    "        r2 = -1\n",
    "        Z_init = ((r1 - r2) * torch.rand(bs, 2 * NT) + r2).to(device=device).double()\n",
    "        sample_list = []\n",
    "\n",
    "        for index, langevin_base in enumerate(self.Langevin_base):\n",
    "            Zi, samples = langevin_base.forward(Z_init, singulars, Sigma, Uh, Vh, y, sigma, self.sigma_gaussian[index], self.sigma_gaussian[-1], bs, step)\n",
    "            sample_list.append(Zi)\n",
    "            Z_init = torch.clone(Zi).to(device=device).double()\n",
    "        return Zi, sample_list[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Unadjusted_langevin_algorithm(nn.Module):\n",
    "#     def __init__(self, NT, generator, n_samples, step, MLPNetwork, device='cuda'):\n",
    "#         super(Unadjusted_langevin_algorithm, self).__init__()\n",
    "#         self.generator = generator\n",
    "#         self.n_samples = n_samples\n",
    "#         self.step = step\n",
    "#         self.device = device\n",
    "#         self.MLP_gradient_likelihood = MLPNetwork\n",
    "\n",
    "#         self.theta = nn.Parameter(torch.normal(0, 0.1, size=(2 * NT)))\n",
    "\n",
    "#         self.GCN_gradient_likelihood = GCN(nnodes = 2 * NT, nfeat=1, nhid=100, noutput= 1, dropout=0.0)\n",
    "#         self.MLP_gradient_likelihood = MLPNetwork(NT, NR, device)\n",
    "\n",
    "class Unadjusted_langevin_algorithm(nn.Module):\n",
    "    def __init__(self, NT, generator, n_samples, device='cuda'):\n",
    "        super(Unadjusted_langevin_algorithm, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.n_samples = n_samples\n",
    "        self.device = device\n",
    "#         self.GCN_gradient_likelihood = GCN(nnodes = 2 * NT, nfeat=1, nhid=100, noutput= 1, dropout=0.0)\n",
    "        self.MLP_gradient_likelihood = MLPNetwork(NT, NR, device)\n",
    "        \n",
    "    def gaussian(self, zt, generator, noise_sigma):\n",
    "        argr = torch.reshape(zt[:,0:NT],[-1,1]) - generator.QAM_const()[0].to(device=device)\n",
    "        argi = torch.reshape(zt[:,NT:],[-1,1]) - generator.QAM_const()[1].to(device=device)\n",
    "\n",
    "        argr = torch.reshape(argr, [-1, NT, M **2]) \n",
    "        argi = torch.reshape(argi, [-1, NT, M **2]) \n",
    "\n",
    "        zt = torch.pow(argr,2) + torch.pow(argi,2)\n",
    "        exp = -1.0 * (zt/(2.0 * noise_sigma**2))\n",
    "        exp = exp.softmax(dim=-1)\n",
    "\n",
    "        xr = torch.mul(torch.reshape(exp,[-1,M **2]).double(), generator.QAM_const()[0].to(device=device))\n",
    "        xi = torch.mul(torch.reshape(exp,[-1,M **2 ]).double(), generator.QAM_const()[1].to(device=device))\n",
    "\n",
    "        xr = torch.reshape(xr, [-1, NT, M **2]).sum(dim=-1)\n",
    "        xi = torch.reshape(xi, [-1, NT, M **2]).sum(dim=-1)\n",
    "        x_out = torch.cat((xr, xi), dim=-1)\n",
    "\n",
    "        return x_out\n",
    "        \n",
    "\n",
    "\n",
    "    ###----Denoiser using mine------###\n",
    "    def forward(self, Z0, singulars, H, Uh, Vh, y, sigma, sigma_gaussian, sigma_L, batch_size, step):\n",
    "\n",
    "        Zi = Z0\n",
    "        samples = []\n",
    "        yT = batch_matvec_mul(Uh, y.double())\n",
    "        del y, Uh\n",
    "        ZT = batch_matvec_mul(Vh, Zi)\n",
    "#         singulars = singulars.to(device=self.device).double()\n",
    "        sgau = torch.unsqueeze(torch.tensor([sigma_gaussian]), dim = 0).repeat(batch_size, 1).to(device=self.device).double()\n",
    "\n",
    "        grad = torch.zeros((batch_size, 2 * NT)).to(device=self.device).double()\n",
    "\n",
    "        for i in range(self.n_samples):\n",
    "            \n",
    "            prior = (self.gaussian(Zi, self.generator, sigma_gaussian**2) - Zi) / sigma_gaussian**2\n",
    "            priorMul = batch_matvec_mul(Vh, prior)\n",
    "            diff =  (yT.double().to(device=self.device) - batch_matvec_mul(H.double().to(device=self.device), ZT.double().to(device=self.device)))\n",
    "            \n",
    "            del prior\n",
    "#             snoise = torch.unsqueeze(torch.tensor([sigma]), dim = 0)\n",
    "#             sigmas = torch.cat((sigma, sgau), dim = 1).to(device=self.device)\n",
    "            input_grad_likelihood = torch.cat((diff, ZT, sgau), dim = 1).to(device=self.device)\n",
    "    \n",
    "            del diff\n",
    "            grad_likelihood = self.MLP_gradient_likelihood.forward(input_grad_likelihood.double()).to(device=self.device)\n",
    "            \n",
    "            grad = grad_likelihood.to(device=self.device) +  priorMul.to(device=self.device)\n",
    "            del grad_likelihood, priorMul, input_grad_likelihood\n",
    "\n",
    "            noiseT = torch.randn(batch_size, 2 * NT).to(device=device)\n",
    "            #4\n",
    "            ZT = ZT + (step  * sigma_gaussian**2 / sigma_L**2) * grad.to(device=self.device) + np.sqrt( (8 * step* sigma_gaussian**2) / sigma_L**2) * noiseT\n",
    "            del noiseT\n",
    "            \n",
    "            Zi = batch_matvec_mul(torch.transpose(Vh, 1, 2), ZT)                                                                                           \n",
    "            samples.append(Zi.cpu().detach().numpy())\n",
    "\n",
    "        return Zi, samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMSE(NT, snr_min, snr_max, batch_size, repeat_sample, generator, device, Cu = None, H=None, iterations = 50):\n",
    "    SNR_dBs = np.linspace(np.int(snr_min), np.int(snr_max), np.int(snr_max - snr_min + 1))\n",
    "    accs_NN = []\n",
    "    real_QAM_const = generator.real_QAM_const.to(device=device)\n",
    "    imag_QAM_const = generator.imag_QAM_const.to(device=device)\n",
    "    bs = repeat_sample * batch_size\n",
    "\n",
    "    H = torch.tensor(H)\n",
    "    H = H.repeat_interleave(repeat_sample, dim=0)\n",
    "    for i in range(SNR_dBs.shape[0]):\n",
    "        acum = 0\n",
    "        print(i)\n",
    "        for jj in range(iterations):\n",
    "            y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H, NT, snr_db_min=SNR_dBs[i], snr_db_max=SNR_dBs[i], batch_size=bs)\n",
    "\n",
    "\n",
    "            H = H.to(device=device).double()\n",
    "            y = y.to(device=device).double()\n",
    "            x = x.to(device=device).double()\n",
    "            j_indices = j_indices.to(device=device).double()        \n",
    "            noise_sigma = noise_sigma.to(device=device).double()\n",
    "\n",
    "            y_MMSE = mmse(y, H, noise_sigma, device).double()\n",
    "\n",
    "            SER_final = sym_detection(y_MMSE, j_indices, real_QAM_const, imag_QAM_const)\n",
    "            acum += SER_final\n",
    "        acum = acum/iterations\n",
    "        accs_NN.append((SNR_dBs[i], 1. - acum))\n",
    "        print([SNR_dBs[i], 1. - acum])\n",
    "        \n",
    "    return accs_NN\n",
    "\n",
    "def sym_detection(x_hat, j_indices, real_QAM_const, imag_QAM_const):\n",
    "    #Convierte a complejo\n",
    "    x_real, x_imag = torch.chunk(x_hat, 2, dim=-1)\n",
    "    #Lo expande a los 4 posibles simbolos para comparar\n",
    "    x_real = x_real.unsqueeze(dim=-1).expand(-1,-1, real_QAM_const.numel())\n",
    "    x_imag = x_imag.unsqueeze(dim=-1).expand(-1,-1, imag_QAM_const.numel())\n",
    "\n",
    "    #Calcula la resta\n",
    "    x_real = torch.pow(x_real - real_QAM_const, 2)\n",
    "    x_imag = torch.pow(x_imag - imag_QAM_const, 2)\n",
    "    x_dist = x_real + x_imag\n",
    "    x_indices = torch.argmin(x_dist, dim=-1)\n",
    "\n",
    "    accuracy = (x_indices == j_indices).sum().to(dtype=torch.float32)\n",
    "    return accuracy.item()/j_indices.numel()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probss(zt, generator, noise_sigma):\n",
    "    argr = torch.reshape(zt[:,0:NT],[-1,1]) - generator.QAM_const()[0].to(device=device)\n",
    "    argi = torch.reshape(zt[:,NT:],[-1,1]) - generator.QAM_const()[1].to(device=device)\n",
    "\n",
    "    argr = torch.reshape(argr, [-1, NT, M **2]) \n",
    "    argi = torch.reshape(argi, [-1, NT, M **2]) \n",
    "\n",
    "    zt = torch.pow(argr,2) + torch.pow(argi,2)\n",
    "#     print(zt.shape, noise_sigma.shape)\n",
    "#     exp = -1.0 * (zt/(2.0 * noise_sigma**2))\n",
    "#     exp = exp.softmax(dim=-1)\n",
    "\n",
    "    return zt\n",
    "\n",
    "\n",
    "def loss_fn(x, list_batch_x_predicted, num_layers, j_indices, real_QAM_const, imag_QAM_const, criterion, ser_only=False):\n",
    "    x_out = torch.cat(list_batch_x_predicted, dim=0)\n",
    "    loss_last = criterion(list_batch_x_predicted[-1].double(), x.double())\n",
    "    x = x.repeat(num_layers, 1)\n",
    "    loss = criterion(x_out.double(), x.double())\n",
    "    SER_final = sym_detection(list_batch_x_predicted[-1].double(), j_indices, real_QAM_const, imag_QAM_const)\n",
    "    return loss, SER_final, loss_last\n",
    "\n",
    "\n",
    "def loss_fn_entropy(x, list_batch_x_predicted, num_layers, j_indices, real_QAM_const, imag_QAM_const, criterion, ser_only=False):\n",
    "    x_out = torch.cat(list_batch_x_predicted, dim=0)\n",
    "    probs = probss(x_out, generator, noise_sigma.expand(1, mod_n).repeat(num_layers,1))\n",
    "    out = probs.permute(0,2,1)\n",
    "    print(out.shape)\n",
    "    j_indices_rep = j_indices.repeat(num_layers, 1)\n",
    "    loss = criterion(out.to(device=device), j_indices_rep.type(torch.LongTensor).to(device=device))\n",
    "    SER_final = sym_detection(list_batch_x_predicted[-1].double(), j_indices, real_QAM_const, imag_QAM_const)\n",
    "    return loss, SER_final\n",
    "\n",
    "def train(H, H_test, model, n_sigma, optimizer, lr_scheduler, generator, step, device='cuda'):\n",
    "    criterion = nn.MSELoss().to(device=device)\n",
    "    model.train()\n",
    "    real_QAM_const = generator.real_QAM_const.to(device=device)\n",
    "    imag_QAM_const = generator.imag_QAM_const.to(device=device)\n",
    "\n",
    "    #######################\n",
    "    ###-------SVD-------###\n",
    "    #######################\n",
    "    U, singulars_test, V = torch.svd(H_test)\n",
    "\n",
    "    Uh_real_test = torch.transpose(U.to(device=device), 1, 2).to(device=device)\n",
    "    Vh_real_test = torch.transpose(V.to(device=device), 1, 2).to(device=device)\n",
    "\n",
    "    Sigma_test = torch.zeros((test_batch_size, 2 * NT, 2 * NT))\n",
    "    for ii in range(test_batch_size):\n",
    "        Sigma_test[ii,:, :] = torch.diag(singulars_test[ii,:])\n",
    "        \n",
    "    index = 0\n",
    "    y_test, x_test, j_indices_test, noise_sigma = generator.give_batch_data_Hinput(H_test, NT, snr_db_min=SNR_dBs[NT][-1], snr_db_max=SNR_dBs[NT][-1], batch_size = test_batch_size)\n",
    "    \n",
    "    for i in range(train_iter):\n",
    "\n",
    "#         print(i)\n",
    "        ########################\n",
    "        #--Samples generation--#\n",
    "        ########################\n",
    "        H, y, x, j_indices, noise_sigma = generator.give_batch_data(NT, snr_db_min=SNR_dBs[NT][0], snr_db_max=SNR_dBs[NT][-1], batch_size=batch_size, correlated_flag=corr_flag, rho=rho)        \n",
    "        y = y.to(device=device).double()\n",
    "        \n",
    "        ######################\n",
    "        ##-------SVD-------###\n",
    "        #######################\n",
    "        U, singulars, V = torch.svd(H)\n",
    "\n",
    "        Uh_real = torch.transpose(U.to(device=device), 1, 2).to(device=device)\n",
    "        Vh_real = torch.transpose(V.to(device=device), 1, 2).to(device=device)\n",
    "\n",
    "        Sigma = torch.zeros((batch_size, 2 * NT, 2 * NT))\n",
    "        for ii in range(batch_size):\n",
    "            Sigma[ii,:, :] = torch.diag(singulars[ii,:])\n",
    "   \n",
    "        ########################\n",
    "        ##---MMSE estimator---##\n",
    "        ########################\n",
    "#         y_MMSE = mmse(y.double().to(device=device), H.double().to(device=device), noise_sigma.double().to(device=device), device).double()\n",
    "\n",
    "        ###############################\n",
    "        ##----Langevin estimator----##\n",
    "        ###############################\n",
    "        noise_sigma = torch.unsqueeze(noise_sigma, dim=-1).to(device=device)\n",
    "        sample_last, samples = model.forward(singulars.double(), Sigma.to(device=device).double(),\n",
    "                                             Uh_real.double(), Vh_real.double(), y, noise_sigma.double(), batch_size, \n",
    "                                                step)\n",
    "\n",
    "        x = x.to(device=device).double()\n",
    "        j_indices = j_indices.to(device=device).double()\n",
    "        loss, SER, loss_level = loss_fn(x, samples, n_sigma-1, j_indices, real_QAM_const, imag_QAM_const, criterion)                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del y, x, j_indices,  sample_last\n",
    "        \n",
    "        if (i%100==0):\n",
    "            model.eval()\n",
    "            y_test = y_test.to(device=device).double()\n",
    "            noise_sigma = noise_sigma.to(device=device).to(device=device).double()\n",
    "#             y_MMSE = mmse(y.double().to(device=device), H_test.double().to(device=device), noise_sigma.double().to(device=device), device).double()\n",
    "            noise_sigma = torch.unsqueeze(noise_sigma, dim=-1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sample_last, samples = model.forward(y_MMSE.double(), singulars_test.double(), Sigma_test.to(device=device).double(),\n",
    "                                                     Uh_real_test.double(), Vh_real_test.double(), y_test, noise_sigma, test_batch_size,\n",
    "                                                    step)\n",
    "                x_test = x_test.to(device=device)\n",
    "                j_indices_test = j_indices_test.to(device=device)\n",
    "#                 print(samples)\n",
    "                loss_last, SER_final, loss_level = loss_fn(x_test, samples,  n_sigma-1, j_indices_test, real_QAM_const, imag_QAM_const, criterion)                \n",
    "                results = [loss_last.detach().item(), 1 - SER_final, loss_level.detach().item()]\n",
    "                print_string = [i]+results\n",
    "                print(' '.join('%s' % np.round(x,6) for x in print_string))\n",
    "                if (i%5000 == 0 and i>0):\n",
    "#                     step = stepvec[index] \n",
    "#                     index = index + 1\n",
    "                    for g in optimizer.param_groups:\n",
    "                        g['lr'] = g['lr'] * 1e-1\n",
    "                    \n",
    "                    lr_scheduler.step(loss_level)\n",
    "#             del y, x, j_indices, noise_sigma, sample_last\n",
    "            model.train()\n",
    "#     torch.save(model.state_dict(), 'MMNet_train')\n",
    "#             print('****************Model Saved*************** at directory : ', model_filename)\n",
    "\n",
    "#     torch.save({'model_state_dict': model.state_dict()}, 'MMNet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sigma_gaussian = 20\n",
    "sigma_0 = 1\n",
    "sigma_L = 1e-2\n",
    "n_sample_init = 100\n",
    "n_sigma_gaussian_trunc = 5\n",
    "\n",
    "sigma_gaussian = np.exp(np.linspace(np.log(sigma_0), np.log(sigma_L),n_sigma_gaussian))\n",
    "\n",
    "batch_size = 500\n",
    "device = 'cuda:0'\n",
    "generator = sample_generator(batch_size, mod_n, NR)\n",
    "SER_lang32u = []\n",
    "SER_MMSE32u_withoutcorr = []\n",
    "n_traj = 1\n",
    "step_size = 3e-5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "test_batch_size = 500\n",
    "train_iter = 20000\n",
    "\n",
    "H = batch_identity_matrix(2 * NR, 2 * NT, 1)\n",
    "# H, y, x, j_indices, noise_sigma = generator.give_batch_data(NT, snr_db_min=SNR_dBs[NT][0], snr_db_max=SNR_dBs[NT][-1], batch_size=1, correlated_flag=corr_flag, rho=rho)        \n",
    "# H = H.repeat_interleave(batch_size, dim=0)\n",
    "# H_test = H_id.repeat_interleave(test_batch_size, dim=0)\n",
    "H_test, y, x, j_indices, noise_sigma = generator.give_batch_data(NT, snr_db_min=SNR_dBs[NT][0], snr_db_max=SNR_dBs[NT][-1], batch_size=test_batch_size, correlated_flag=corr_flag, rho=rho)        \n",
    "# H_test = torch.clone(H)\n",
    "\n",
    "model = Langevin(NT, sigma_gaussian, generator, n_sample_init, device='cuda')\n",
    "model.load_state_dict(torch.load('model_learning_64x32_16qam_3lr.pth'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min', 0.91, 0, 0.0001, 'rel', 0, 0, 1e-08, verbose = True)\n",
    "\n",
    "# train(H, H_test, model, n_sigma_gaussian ,optimizer,lr_scheduler , generator, step_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "step_size = 3e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min', 0.91, 0, 0.0001, 'rel', 0, 0, 1e-08, verbose = True)\n",
    "\n",
    "train(H, H_test, model, n_sigma_gaussian ,optimizer,lr_scheduler , generator, step_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_learning_64x32_16qam_3lr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "step_size = 3e-5\n",
    "H_test2, y, x, j_indices, noise_sigma = generator.give_batch_data(NT, snr_db_min=SNR_dBs[NT][-3], snr_db_max=SNR_dBs[NT][-3], batch_size=batch_size, correlated_flag=corr_flag, rho=rho)        \n",
    "######################\n",
    "##-------SVD-------###\n",
    "#######################\\\n",
    "y = y.to(device=device).double()\n",
    "\n",
    "y_MMSE = torch.ones((batch_size, 2 * NT)).double().to(device=device)\n",
    "\n",
    "U, singulars, V = torch.svd(H_test2)\n",
    "\n",
    "Uh_real = torch.transpose(U.to(device=device), 1, 2).to(device=device)\n",
    "Vh_real = torch.transpose(V.to(device=device), 1, 2).to(device=device)\n",
    "\n",
    "Sigma = torch.zeros((batch_size, 2 * NT, 2 * NT))\n",
    "for ii in range(batch_size):\n",
    "    Sigma[ii,:, :] = torch.diag(singulars[ii,:])\n",
    "            \n",
    "noise_sigma = torch.unsqueeze(noise_sigma, dim=-1).to(device=device)\n",
    "\n",
    "start = time.time()\n",
    "sample_last, samples = model.forward(y_MMSE.double(), singulars.double(), Sigma.to(device=device).double(),\n",
    "                                             Uh_real.double(), Vh_real.double(), y, noise_sigma.double(), batch_size, step_size)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "print(1 - sym_detection(sample_last.double(), j_indices.to(device=device), generator.real_QAM_const.to(device=device), generator.imag_QAM_const.to(device=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.828251600265503\n",
      "4.914945602416992\n",
      "4.993597030639648\n",
      "5.141162395477295\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 39.59 GiB total capacity; 30.74 GiB already allocated; 3.44 MiB free; 31.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2453605/584541369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#         with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         sample_last, samples = model.forward(y_MMSE.double(), singulars.double(), Sigma.to(device=device).double(),\n\u001b[0m\u001b[1;32m     45\u001b[0m                                                  Uh_real.double(), Vh_real.double(), y, noise_sigma.double(), batch_size, step_size)\n\u001b[1;32m     46\u001b[0m         \u001b[0mlist_traj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_last\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2453605/1431143290.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Z0, singulars, Sigma, Uh, Vh, y, sigma, bs, step)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlangevin_base\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLangevin_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mZi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlangevin_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingulars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_gaussian\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_gaussian\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0msample_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mZ_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2453605/502296422.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_gaussian\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma_gaussian\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mpriorMul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_matvec_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0myT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_matvec_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2453605/502296422.py\u001b[0m in \u001b[0;36mgaussian\u001b[0;34m(self, zt, generator, noise_sigma)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0margr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQAM_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0margi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQAM_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 39.59 GiB total capacity; 30.74 GiB already allocated; 3.44 MiB free; 31.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "## with open(\"H_5000bs_1664\", \"rb\") as output_file:\n",
    "#     H_test2 = pkl.load(output_file)\n",
    "# with open('/home/nicolas/MIMO_detection_project/Langevin_local_repo/data/H_5000bs_3264', 'rb') as fp:\n",
    "#         H_test2 = pkl.load(fp) \n",
    "SER_lang32u = []\n",
    "n_traj = 20\n",
    "batch_size = 100\n",
    "step_size = 3e-5\n",
    "snr = -1\n",
    "H_test2, y, x, j_indices, noise_sigma = generator.give_batch_data(NT, snr_db_min=SNR_dBs[NT][snr], snr_db_max=SNR_dBs[NT][snr], batch_size=batch_size, correlated_flag=corr_flag, rho=rho)        \n",
    "snr_value = SNR_dBs[NT][snr]\n",
    "# y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H_test2, NT, snr_db_min=snr_value, snr_db_max=snr_value, batch_size = batch_size)\n",
    "######################\n",
    "##-------SVD-------###\n",
    "#######################\\\n",
    "y = y.to(device=device).double()\n",
    "\n",
    "y_MMSE = torch.ones((batch_size, 2 * NT)).double().to(device=device)\n",
    "\n",
    "U, singulars, V = torch.svd(H_test2)\n",
    "\n",
    "Uh_real = torch.transpose(U.to(device=device), 1, 2).to(device=device)\n",
    "Vh_real = torch.transpose(V.to(device=device), 1, 2).to(device=device)\n",
    "\n",
    "Sigma = torch.zeros((batch_size, 2 * NT, 2 * NT))\n",
    "for ii in range(batch_size):\n",
    "    Sigma[ii,:, :] = torch.diag(singulars[ii,:])\n",
    "            \n",
    "noise_sigma = torch.unsqueeze(noise_sigma, dim=-1).to(device=device)\n",
    "\n",
    "for snr in range(5, len(SNR_dBs[NT])):\n",
    "    dist = torch.zeros((batch_size,n_traj)).to(device='cpu')\n",
    "    list_traj = torch.zeros((batch_size, 2*NT, n_traj)).to(device='cpu')\n",
    "    x_hat = torch.zeros((batch_size, 2*NT)).to(device='cpu')\n",
    "    ###############################\n",
    "    ##----Langevin estimator----##\n",
    "    #--Generate n_traj realizations of Langevin and then choose the best one w.r.t to ||y-Hx||^2--#\n",
    "    ###############################\n",
    "    y, x, j_indices, noise_sigma = generator.give_batch_data_Hinput(H_test2, NT, snr_db_min=SNR_dBs[NT][snr], snr_db_max=SNR_dBs[NT][snr], batch_size = batch_size)\n",
    "\n",
    "    for jj in range(0, n_traj):\n",
    "        start = time.time()\n",
    "#         with torch.no_grad():\n",
    "        sample_last, samples = model.forward(y_MMSE.double(), singulars.double(), Sigma.to(device=device).double(),\n",
    "                                                 Uh_real.double(), Vh_real.double(), y, noise_sigma.double(), batch_size, step_size)\n",
    "        list_traj[:,:,jj] = torch.clone(sample_last.to(device='cpu'))\n",
    "        dist[:, jj] = torch.norm(y.to(device='cpu').float() - batch_matvec_mul(H_test2.to(device='cpu').float(), sample_last.to(device='cpu').float()), 2, dim = 1)\n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        torch.cuda.empty_cache()\n",
    "    #         print(1 - sym_detection(sample_last.to(device='cpu'), j_indices, generator.real_QAM_const, generator.imag_QAM_const))\n",
    "\n",
    "    idx = torch.argsort(dist, dim=1, descending = False)\n",
    "\n",
    "    for nnn in range(0, batch_size):\n",
    "        x_hat[nnn, :] = torch.clone(list_traj[nnn,:,idx[nnn,0]])\n",
    "\n",
    "    #     Detection   \n",
    "    SER_lang32u.append(1 - sym_detection(x_hat.to(device='cpu'), j_indices, generator.real_QAM_const, generator.imag_QAM_const))\n",
    "    print(SER_lang32u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langtrue = [0.0686, 0.0305, 0.011, 0.003 , 0.001 ,0.00018, 6e-5]\n",
    "langtrue = [0.098, 0.062, 0.033, 0.022 , 0.01 , 0.0035, 0.0016]\n",
    "langtrue = [0.076, 0.036, 0.016, 0.0052,0.0014,0.00033]\n",
    "plt.semilogy(SNR_dBs[NT], langtrue, label= 'Langevin', marker = '*')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.legend(loc = 1, fontsize=15)\n",
    "plt.xlabel('SNR', fontsize=15)\n",
    "plt.ylabel('SER', fontsize=15)\n",
    "plt.tick_params(axis='both' , labelsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.zeros((n_sigma_gaussian * (n_sample_init), 2, 2*NT))\n",
    "\n",
    "for ii in range(n_sigma_gaussian-1):\n",
    "    aa[0 + ii*(len(samples[ii].cpu().detach().numpy())):(len(samples[ii].cpu().detach().numpy())) + ii*(len(samples[ii])),:,:] = samples[ii].cpu().detach().numpy()\n",
    "    \n",
    "import matplotlib.animation as animation\n",
    "r1 = 0.15\n",
    "r2 = 0.25\n",
    "uu = (r1 - r2) * torch.rand(NT) + r2\n",
    "uu = 0\n",
    "initval = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlim([-2,2])\n",
    "plt.ylim([-2,2])\n",
    "p, = plt.plot(aa[initval][0,0:NT], aa[initval][0,NT:], \"o\")\n",
    "p2, = plt.plot(generator.QAM_const()[0] + uu,  generator.QAM_const()[1], \"o\", color='red')\n",
    "p3, = plt.plot(aa[-1][0,0:NT], aa[-1][0,NT:], \"o\", color='green')\n",
    "# p4, = plt.plot(y_MMSE[0,0:NT], y_MMSE[0,NT:], \"o\", color='yellow')\n",
    "p5, = plt.plot(x[0,0:NT] + uu, x[0,NT:] + uu, \"o\", color='orange')\n",
    "\n",
    "# p5, = plt.plot(samples_denoiserMMNet[initval][0,0:NT], samples_denoiserMMNet[initval][0,NT:], \"o\", color='orange')\n",
    "\n",
    "def update(frame):\n",
    "#     print(frame)\n",
    "    p.set_data(aa[frame + initval][0,0:NT], aa[frame + initval][0,NT:])\n",
    "    p2.set_data( generator.QAM_const()[0],  generator.QAM_const()[1])\n",
    "    p3.set_data(aa[-1][0,0:NT], aa[-1][0,NT:])\n",
    "#     p4.set_data(y_MMSE[0,0:NT], y_MMSE[0,NT:])\n",
    "    p5.set_data(x[0,0:NT] + uu, x[0,NT:] + uu)\n",
    "\n",
    "#     p5.set_data(samples_denoiserMMNet[frame + initval][0,0:NT], samples_denoiserMMNet[frame + initval][0,NT:])\n",
    "\n",
    "    return p, p2, p3, p5\n",
    "\n",
    "def init():\n",
    "    p.set_data(aa[initval][0,0:NT], aa[initval][0,NT:])\n",
    "    p2.set_data(generator.QAM_const()[0], generator.QAM_const()[1])\n",
    "    p3.set_data(aa[-1][0,0:NT], aa[-1][0,NT:])\n",
    "#     p4.set_data(y_MMSE[0,0:NT], y_MMSE[0,NT:])\n",
    "    p5.set_data(x[0,0:NT] + uu, x[0,NT:] + uu)\n",
    "\n",
    "#     p5.set_data(samples_denoiserMMNet[initval][0,0:NT], samples_denoiserMMNet[initval][0,NT:])\n",
    "    \n",
    "    return  p, p2, p3, p5\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig=fig, func=update, init_func=init,  frames=n_sigma_gaussian * (n_sample_init), interval=1)\n",
    "plt.show()\n",
    "ani.save('5.gif', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
